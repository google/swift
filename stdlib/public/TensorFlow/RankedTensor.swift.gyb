//===-- RankedTensor.swift.gyb --------------------------------*- swift -*-===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2017 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//
//
// Dynamically shaped but statically ranked tensors.
//
// Ranked tensors (Tensor1D, Tensor2D, etc) use an array of integers to
// represent a shape with known rank. The number of dimensions is guaranteed to
// equal the rank of the tensor.
//
//===----------------------------------------------------------------------===//

infix operator âŠ— : MultiplicationPrecedence

%{
  ranks = [1, 2, 3, 4]

  def rankName(rank):
    if rank == 1:
      return 'one'
    elif rank == 2:
      return 'two'
    elif rank == 3:
      return 'three'
    elif rank == 4:
      return 'four'

  def _elementArrayLiteral(rank):
    return 'Scalar' if rank == 1 else 'Tensor{}D<Scalar>'.format(rank-1)
}%

% for rank in ranks:
%   elementRank = rank - 1
%   liftedRank = rank + 1
%   TensorXD = 'Tensor{}D'.format(rank)
%   ArrayXD = 'Array{}D'.format(rank)
%   ElementTensor = 'Tensor{}D'.format(elementRank)
%   LiftedTensor = 'Tensor{}D'.format(liftedRank)
%   elementArrayLiteral = _elementArrayLiteral(rank)

/// A ${rankName(rank)}-dimensional tensor.
public struct ${TensorXD}<Scalar : AccelerableByTensorFlow> {
  /// The underlying Tensor of the ${TensorXD}.
  @_versioned
  internal var base: Tensor<Scalar>

  @_inlineable
  public static var rank: Int {
    @inline(__always)
    get {
      return ${rank}
    }
  }

  @_inlineable
  public var rank: Int {
    @inline(__always)
    get {
      return ${rank}
    }
  }

  /// - TODO(danielzheng): Add an 'array' property, which returns a RankedArray
  /// (to be implemented in Arrays.swift.gyb).
  @_inlineable
  public var scalars: [Scalar] {
    @inline(__always)
    get {
      return base.scalars
    }
  }

  @_inlineable
  public var scalarCount: Int {
    @inline(__always)
    get {
      return base.scalarCount
    }
  }

  @_inlineable
  public var handle: TensorHandle<Scalar> {
    @inline(__always)
    get {
      return base.handle
    }
  }

  @_inlineable
  public var shape: TensorShape {
    @inline(__always)
    get {
      return base.shape
    }
  }

  /// Creates a ${TensorXD} from a Tensor.
  /// - Note: This is an internal initializer and should not be exposed to
  ///   users.
  @_versioned
  @_inlineable @inline(__always)
  internal init(base: Tensor<Scalar>) {
    self.init()
    self.base = base
  }

  @_inlineable @inline(__always)
  public init(handle: TensorHandle<Scalar>) {
    self.init(base: Tensor(handle: handle))
  }

  /// Creates a ${TensorXD} from a Tensor. Returns nil if the Tensor does not
  /// have rank ${rank}.
  @_inlineable @inline(__always)
  public init?(_ other: Tensor<Scalar>) {
    guard other.rank == ${rank} else { return nil }
    self.init(base: other)
  }

  /// Creates a ${TensorXD} from a Tensor.
  /// - Precondition: The tensor must have rank ${rank}.
  @_inlineable @inline(__always)
  public init(identicallyRanked other: Tensor<Scalar>) {
    // NOTE: Assertion disabled because `other.rank` causes a copy of `other`
    // back to the host. Uncomment precondition when send/receive is
    // implemented.
    // TODO(clattner): need a better way of exposing rank information in our
    // model.
    // precondition(other.rank == ${rank}, "Rank is not ${rank}.")
    self.init(base: other)
  }
}

/// Array literal support.
extension ${TensorXD} : ExpressibleByArrayLiteral {
  /// Creates a ${TensorXD} from with the specified elements.
  @_inlineable @inline(__always)
  public init(arrayLiteral elements: ${elementArrayLiteral}...) {
    self.init(elements)
  }
}

public extension ${TensorXD} where Scalar : Numeric {
  /// Perform an element-wise type conversion from ${TensorXD}<T>.
  @_inlineable @inline(__always)
  init<FromType : Numeric>(_ other: ${TensorXD}<FromType>) {
    self.init(base: Tensor<Scalar>(other.base))
  }

  /// Perform an element-wise type conversion from ${TensorXD}<Bool>.
  @_inlineable @inline(__always)
  init(_ other: ${TensorXD}<Bool>) {
    self.init(base: Tensor<Scalar>(other.base))
  }
}

/// Initializers
public extension ${TensorXD} {
  /// Creates a ${TensorXD} from a ShapedArray. Returns nil if the ShapedArray
  /// does not have rank ${rank}.
  @_inlineable @inline(__always)
  init?(_ other: ShapedArray<Scalar>) {
    self.init(Tensor(other))
  }

  /// Creates a ${TensorXD} from a ShapedArray.
  /// - Precondition: The ShapedArray must have rank ${rank}.
  @_inlineable @inline(__always)
  init(identicallyRanked other: ShapedArray<Scalar>) {
    self.init(identicallyRanked: Tensor(other))
  }

% if rank != 1:
  /// Creates a ${TensorXD} from an ${ArrayXD}.
  @_inlineable @inline(__always)
  init(_ other: ${ArrayXD}<Scalar>) {
    self.init(base: Tensor(other.base))
  }
% end

  /// Creates a ${TensorXD} containing the given element literals.
  @_inlineable @inline(__always)
  init(_ scalars: [${elementArrayLiteral}]) {
    self.init(base: Tensor<Scalar>(scalars))
  }

  /// Creates a ${TensorXD} containing the given element literals.
  @_inlineable @inline(__always)
  init(_ scalars: ${elementArrayLiteral}...) {
    self.init(scalars)
  }
}

public extension AccelerableByTensorFlow {
  /// Converts to a ${TensorXD} with all dimensions equal to 1.
  @_inlineable @inline(__always)
  func make${TensorXD}() -> ${TensorXD}<Self> {
    return ${TensorXD}(base: self.makeTensor(withRank: ${rank}))
  }
}

/// Memory transfer markers
/// - TODO: Remove when send/receive semantics gets revisited.
public extension ${TensorXD} {
  /// Indicate that this tensor is being moved to the accelerator.
  @_inlineable @inline(__always)
  func toDevice() -> ${TensorXD} {
    return ${TensorXD}(base: base.toDevice())
  }

  /// Indicate that this tensor is being moved to the host.
  @_inlineable @inline(__always)
  func toHost() -> ${TensorXD} {
    return ${TensorXD}(base: base.toHost())
  }
}

/// Factories
public extension ${TensorXD} where Scalar : Numeric {
  /// Creates a ${TensorXD} with all elements set to zero.
  ///
  /// - Parameter shape: The dimensions of the ${TensorXD}.
  @_inlineable @inline(__always)
  init(zeros shape: TensorShape) {
    // TODO: Uncomment precondition when `.count` is reliably constant folded.
    // precondition(shape.count == ${rank},
    //              "Rank is not ${rank}")
    self.init(base: Tensor<Scalar>(zeros: shape))
  }

  /// Creates a ${TensorXD} with all elements set to one.
  ///
  /// - Parameter shape: The dimensions of the ${TensorXD}.
  @_inlineable @inline(__always)
  init(ones shape: TensorShape) {
    // TODO: Uncomment precondition when `.count` is reliably constant folded.
    // precondition(shape.count == ${rank},
    //              "Rank is not ${rank}")
    self.init(base: Tensor<Scalar>(ones: shape))
  }
}

public extension ${TensorXD} where Scalar : FloatingPoint {
  /// Creates a ${TensorXD} with the specified shape, randomly sampling
  /// scalar values from a normal distribution.
  ///
  /// - Parameters:
  ///   - shape: The dimensions of the ${TensorXD}.
  ///   - mean: The mean of the distribution.
  ///   - stddev: The standard deviation of the distribution.
  ///   - seed: A random seed for the operation.
  ///
  @_inlineable @inline(__always)
  init(
    randomNormal shape: TensorShape, mean: Double = 0, stddev: Double = 1,
    seed: Int32 = 0
  ) {
    self.init(
      base: Tensor<Scalar>(
        randomNormal: shape, mean: mean, stddev: stddev, seed: seed
      )
    )
  }
}

//===----------------------------------------------------------------------===//
// Transforms
//===----------------------------------------------------------------------===//

public extension ${TensorXD} {
  /// Returns a transposed ${TensorXD}, with dimensions permuted in reverse
  /// order.
  @_inlineable @inline(__always)
  func transposed() -> ${TensorXD} {
    let defaultPermutations = (rankTensor - 1) - Tensor<Int32>(
    rangeFrom: Tensor<Int32>(handle: _TFMakeScalarTensor(0)),
      to: rankTensor,
      stride: Tensor<Int32>(handle: _TFMakeScalarTensor(1))
    )
    return transposed(withPermutations: defaultPermutations)
  }
}

//===----------------------------------------------------------------------===//
// Indexing and slicing
//===----------------------------------------------------------------------===//

public extension ${TensorXD} {
% if rank == 1:
  @_inlineable
  /// Access the scalar specified by a given index.
  /// - Parameter index: Index of the scalar.
  subscript(index: Int) -> Scalar {
    @inline(never) get {
      fatalError("Unimplemented")
    }
    @inline(never )set {
      fatalError("Unimplemented")
    }
  }
% else:
  @_inlineable
  /// Access the element ${ElementTensor} specified by an index in the leading
  /// dimension.
  /// - Parameter index: Index of the element ${ElementTensor}.
  subscript(index: Int) -> ${ElementTensor}<Scalar> {
    @inline(__always)
    get {
      return ${ElementTensor}<Scalar>(base: base[index])
    }
    @inline(__always)
    set {
      base[index] = newValue.base
    }
  }
% end

  /// Access the subtensor specified by a contiguous range of indices.
  /// - Parameter bounds: Contiguous range of indices.
  //  - TODO: begin/end are vectors in general.
  // tfop_slice(tensor, begin, end) -> tensor
  subscript(bounds: Range<Int>) -> ${TensorXD} {
    get {
      fatalError("FIXME: implement subscript to tensor")
    }
    set {
      fatalError("FIXME: implement subscript to tensor")
    }
  }
}

//===----------------------------------------------------------------------===//
// Reduction
//===----------------------------------------------------------------------===//

public extension ${TensorXD} where Scalar : Numeric {
% if rank > 1:
  @_inlineable @inline(__always)
  func min(alongAxis axis: Int32) -> ${ElementTensor}<Scalar> {
    return ${ElementTensor}<Scalar>(base: base.min(alongAxes: [axis]))
  }

  @_inlineable @inline(__always)
  func max(alongAxis axis: Int32) -> ${ElementTensor}<Scalar> {
    return ${ElementTensor}<Scalar>(base: base.max(alongAxes: [axis]))
  }

  @_inlineable @inline(__always)
  func sum(alongAxis axis: Int32) -> ${ElementTensor}<Scalar> {
    return ${ElementTensor}<Scalar>(base: base.sum(alongAxes: [axis]))
  }

  @_inlineable @inline(__always)
  func mean(alongAxis axis: Int32) -> ${ElementTensor}<Scalar> {
    return ${ElementTensor}<Scalar>(base: base.mean(alongAxes: [axis]))
  }
% end
}

public extension ${TensorXD} {
% if rank < ranks[-1]:
  /// Returns a rank-lifted {LiftedTensor} with a leading dimension of 1.
  @_inlineable @inline(__always)
  func rankLifted() -> ${LiftedTensor}<Scalar> {
    return ${LiftedTensor}<Scalar>(base: base.rankLifted())
  }

  /// Returns a shape-padded {LiftedTensor}, inserting a dimension of 1 at the
  /// specified index.
  @_inlineable @inline(__always)
  func shapePadded(atIndex index: Int32) -> ${LiftedTensor}<Scalar> {
    return ${LiftedTensor}<Scalar>(base: base.shapePadded(atIndex: index))
  }
% end
}

//===----------------------------------------------------------------------===//
// Description and visualization
//===----------------------------------------------------------------------===//

/// Make "print(some${TensorXD})" print a pretty form of the tensor.
extension ${TensorXD} : CustomStringConvertible {
  @_inlineable
  public var description: String {
    return base.description
  }
}

/// Make ${TensorXD}s show up nicely in the Xcode Playground results sidebar.
extension ${TensorXD} : CustomPlaygroundQuickLookable {
  @_inlineable
  public var customPlaygroundQuickLook: PlaygroundQuickLook {
    return .text(description)
  }
}

//===----------------------------------------------------------------------===//
// Array conversion
//===----------------------------------------------------------------------===//

public extension ${TensorXD} {
  @_inlineable
  var array: ${ArrayXD}<Scalar> {
    @inline(__always)
    get {
      // This is considered to be a well known way to produce a copy to the
      // host, so an "implicit copy to host" warning should not be produced.
% if rank == 1:
      return base.scalars
% else:
      return ${ArrayXD}(base: base.array)
% end
    }
  }
}
% end

//===----------------------------------------------------------------------===//
// Tensor conversion
//===----------------------------------------------------------------------===//

/// Value-preserving conversion initializer
public extension Tensor {
% for rank in ranks:
%   TensorXD = 'Tensor{}D'.format(rank)
  @_inlineable @inline(__always)
  init(_ tensor: ${TensorXD}<Scalar>) {
    self = tensor.base
  }
% end
}
