//===-- RankedTensor.swift.gyb --------------------------------*- swift -*-===//
//
// This source file is part of the Swift.org open source project
//
// Copyright (c) 2014 - 2017 Apple Inc. and the Swift project authors
// Licensed under Apache License v2.0 with Runtime Library Exception
//
// See https://swift.org/LICENSE.txt for license information
// See https://swift.org/CONTRIBUTORS.txt for the list of Swift project authors
//
//===----------------------------------------------------------------------===//
//
// Dynamically shaped but statically ranked tensors.
//
// Ranked tensors (Tensor1D, Tensor2D, etc) use an array of integers to
// represent a shape with known rank. The length of the shape is guaranteed to
// equal the rank of the tensor.
//
//===----------------------------------------------------------------------===//

infix operator âŠ— : MultiplicationPrecedence

%{
  ranks = [1, 2, 3, 4]

  def rankName(rank):
    if rank == 1:
         return 'one'
    elif rank == 2:
         return 'two'
    elif rank == 3:
         return 'three'
    elif rank == 4:
         return 'four'

  def _elementArrayLiteral(rank):
    return 'Scalar' if rank == 1 else 'Tensor{}D<Scalar>'.format(rank-1)
}%

% for rank in ranks:
%   elementRank = rank - 1
%   liftedRank = rank + 1
%   Self = 'Tensor{}D'.format(rank)
%   ElementTensor = 'Tensor{}D<Scalar>'.format(elementRank)
%   LiftedTensor = 'Tensor{}D<Scalar>'.format(liftedRank)
%   elementArrayLiteral = _elementArrayLiteral(rank)

/// A ${rankName(rank)}-dimensional tensor.
public struct ${Self}<Scalar : AccelerableByTensorFlow> {
  public var base: Tensor<Scalar>

  @_inlineable
  public static var rank: Int {
    @inline(__always)
    get {
      return ${rank}
    }
  }

  @_inlineable
  public var rank: Int {
    @inline(__always)
    get {
      return ${Self}.rank
    }
  }

  /// - TODO(danielzheng): Add an 'array' property, which returns a RankedArray
  /// (to be implemented in Arrays.swift.gyb).
  @_inlineable
  public var scalars: [Scalar] {
    @inline(__always)
    get {
      return base.scalars
    }
  }

  @_inlineable
  public var scalarCount: Int {
    @inline(__always)
    get {
      return base.scalarCount
    }
  }

  @_inlineable
  public var handle: TensorHandle<Scalar> {
    @inline(__always)
    get {
      return base.handle
    }
  }

  @_inlineable
  public var shape: TensorShape {
    @inline(__always)
    get {
      return base.shape
    }
  }

  @_versioned
  @_inlineable @inline(__always)
  internal init(base: Tensor<Scalar>) {
    self.base = base
  }

  @_inlineable @inline(__always)
  public init(handle: TensorHandle<Scalar>) {
    self.init(base: Tensor(handle: handle))
  }

  @_inlineable @inline(__always)
  public init?(_ other: Tensor<Scalar>) {
    guard other.rank == ${Self}.rank else { return nil }
    self.init(base: other)
  }

  @_inlineable @inline(__always)
  public init(identicallyRanked other: Tensor<Scalar>) {
    // Assertion disabled because "x.rank" causes a copy of X
    // back to the host. TODO(clattner): need a better way of
    // exposing rank information in our model.
    // precondition(other.rank == ${Self}.rank, "Rank is not ${rank}")
    self.init(base: other)
  }
}

/// Array literal support.
extension ${Self} : ExpressibleByArrayLiteral {
  /// Creates an instance initialized with the given elements.
  @_inlineable @inline(__always)
  public init(arrayLiteral elements: ${elementArrayLiteral}...) {
    self.init(elements)
  }
}

/// Perform an element-wise type conversion from `${Self}<T>`.
extension ${Self} where Scalar : Numeric {
  @_inlineable @inline(__always)
  public init<T : Numeric>(_ other: ${Self}<T>) {
    self.init(base: Tensor<Scalar>(other.base))
  }
}

/// Initializers
public extension ${Self} {
  /// Convert from a ShapedArray. Returns nil when the ShapedArray has the wrong
  /// rank.
  @_inlineable @inline(__always)
  init?(_ other: ShapedArray<Scalar>) {
    self.init(Tensor(other))
  }

  /// Convert from a ShapedArray.
  /// - Precondition: The ShapedArray must have rank ${rank}.
  @_inlineable @inline(__always)
  init(identicallyRanked other: ShapedArray<Scalar>) {
    self.init(identicallyRanked: Tensor(other))
  }

  /// Creates an instance initialized with the given element literals.
  @_inlineable @inline(__always)
  init(_ scalars: [${elementArrayLiteral}]) {
    self.init(base: Tensor<Scalar>(scalars))
  }

  /// Creates an instance initialized with the given element literals.
  @_inlineable @inline(__always)
  init(_ scalars: ${elementArrayLiteral}...) {
    self.init(scalars)
  }

  /// Creates an instance initialized with a scalar.
  @_inlineable @inline(__always)
  init(_ value: Scalar) {
    base = Tensor(value)
  }
}

/// Memory transfer markers
/// - TODO: Remove when send/receive semantics gets revisited.
public extension ${Self} {
  /// Indicate that this tensor is being moved to the accelerator.
  @_inlineable @inline(__always)
  func toDevice() -> ${Self} {
    return ${Self}(base: base.toDevice())
  }

  /// Indicate that this tensor is being moved to the host.
  @_inlineable @inline(__always)
  func toHost() -> ${Self} {
    return ${Self}(base: base.toHost())
  }
}

/// Factories
public extension ${Self} where Scalar : Numeric {
  /// Initialize a ${rank}D tensor with all elements set to zero.
  ///
  /// - Parameter shape: the sizes of the tensor along each dimension.
  @_inlineable @inline(__always)
  init(zeros shape: TensorShape) {
    // TODO: Uncomment precondition when `.count` is reliably constant folded.
    // precondition(shape.count == ${Self}.rank,
    //              "Rank is not ${rank}")
    self.init(base: Tensor<Scalar>(zeros: shape))
  }

  /// Initialize a ${rank}D tensor with all elements set to one.
  ///
  /// - Parameter shape: the sizes of the tensor along each dimension.
  @_inlineable @inline(__always)
  init(ones shape: TensorShape) {
    // TODO: Uncomment precondition when `.count` is reliably constant folded.
    // precondition(shape.count == ${Self}.rank,
    //              "Rank is not ${rank}")
    self.init(base: Tensor<Scalar>(ones: shape))
  }
}

public extension ${Self} where Scalar : FloatingPoint {
  @_inlineable @inline(__always)
  static func randomNormal(
    shape: [Int32], mean: Double = 0, stddev: Double = 1
  ) -> ${Self} {
    return ${Self}(base:
      Tensor<Scalar>.randomNormal(
        shape: shape,
        mean: mean,
        stddev: stddev
      )
    )
  }
}

//===----------------------------------------------------------------------===//
// Transforms
//===----------------------------------------------------------------------===//

public extension ${Self} {
  /// Returns a transposed tensor, with dimensions permuted in reverse order.
  @_inlineable @inline(__always)
  func transposed() -> ${Self} {
    let defaultPermutations = (rankTensor - 1) - Tensor<Int32>(
    rangeFrom: Tensor<Int32>(handle: _TFMakeScalarTensor(0)),
      to: rankTensor,
      stride: Tensor<Int32>(handle: _TFMakeScalarTensor(1))
    )
    return transposed(withPermutations: defaultPermutations)
  }
}

//===----------------------------------------------------------------------===//
// Indexing and slicing
//===----------------------------------------------------------------------===//

public extension ${Self} {
% if rank == 1:
  @_inlineable
  /// Access the scalar specified by a given index.
  /// - Parameter index: index of the scalar
  subscript(index: Int) -> Scalar {
    @inline(never) get {
      fatalError("Unimplemented")
    }
    @inline(never )set {
      fatalError("Unimplemented")
    }
  }
% else:
  @_inlineable
  /// Access the element ${ElementTensor} specified by an index in the leading dimension.
  /// - Parameter index: index of the element tensor
  subscript(index: Int) -> ${ElementTensor} {
    @inline(__always)
    get {
      return ${ElementTensor}(base: base[index])
    }
    @inline(__always)
    set {
      base[index] = newValue.base
    }
  }
% end

  /// Returns the subtensor defined by the specified bounds.
  /// - Parameter bounds: contiguous range of indices
  //  - TODO: begin/end are vectors in general.
  // tfop_slice(tensor, begin, end) -> tensor
  subscript(bounds: Range<Int>) -> ${Self} {
    get {
      fatalError("FIXME: implement subscript to tensor")
    }
    set {
      fatalError("FIXME: implement subscript to tensor")
    }
  }
}

//===----------------------------------------------------------------------===//
// Reduction
//===----------------------------------------------------------------------===//

public extension ${Self} where Scalar : Numeric {
% if rank > 1:
  @_inlineable @inline(__always)
  func min(alongAxis axis: Int32) -> ${ElementTensor} {
    return ${ElementTensor}(base: base.min(alongAxes: [axis]))
  }

  @_inlineable @inline(__always)
  func max(alongAxis axis: Int32) -> ${ElementTensor} {
    return ${ElementTensor}(base: base.max(alongAxes: [axis]))
  }

  @_inlineable @inline(__always)
  func sum(alongAxis axis: Int32) -> ${ElementTensor} {
    return ${ElementTensor}(base: base.sum(alongAxes: [axis]))
  }

  @_inlineable @inline(__always)
  func mean(alongAxis axis: Int32) -> ${ElementTensor} {
    return ${ElementTensor}(base: base.mean(alongAxes: [axis]))
  }
% end
}

/// Make "print(some${Self})" print a pretty form of the tensor.
extension ${Self} : CustomStringConvertible {
  @_inlineable
  public var description: String {
    return base.description
  }
}

/// Make ${Self}s show up nicely in the Xcode Playground results sidebar.
extension ${Self} : CustomPlaygroundQuickLookable {
  @_inlineable
  public var customPlaygroundQuickLook: PlaygroundQuickLook {
    return .text(description)
  }
}

public extension ${Self} {
% if rank < ranks[-1]:
  /// Returns a rank-lifted Tensor${liftedRank}D with a leading dimension of 1.
  @_inlineable @inline(__always)
  func rankLifted() -> ${LiftedTensor} {
    return ${LiftedTensor}(base: base.rankLifted())
  }

  /// Returns a shape-padded Tensor${liftedRank}D, inserting a dimension of 1
  /// at a given index.
  @_inlineable @inline(__always)
  func shapePadded(atIndex index: Int32) -> ${LiftedTensor} {
    return ${LiftedTensor}(base: base.shapePadded(atIndex: index))
  }
% end
}
% end

/// Value-preserving conversion initializer
public extension Tensor {
% for rank in ranks:
%   Self = 'Tensor{}D'.format(rank)
  @_inlineable @inline(__always)
  init(_ tensor: ${Self}<Scalar>) {
    self = tensor.base
  }
% end
}
